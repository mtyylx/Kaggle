{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from utils import get_params_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.applications import inception_v3, xception, resnet50, vgg16, vgg19\n",
    "from keras.applications import InceptionV3, Xception, ResNet50, VGG16, VGG19\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10222, Test: 10357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 10222/10222 [00:27<00:00, 373.32it/s]\n",
      "100%|█████████████████████████████████████████████████████| 10357/10357 [00:27<00:00, 381.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 5.73 GB\n",
      "Testing Data Size = 5.81 GB\n"
     ]
    }
   ],
   "source": [
    "height = 224\n",
    "train_name = os.listdir('./train')\n",
    "test_name = os.listdir('./test')\n",
    "train_size = len(train_name)\n",
    "test_size = len(test_name)\n",
    "train = np.zeros((train_size, height, height, 3), dtype=np.float32)\n",
    "test = np.zeros((test_size, height, height, 3), dtype=np.float32)\n",
    "print(\"Train: %d, Test: %d\" % (train_size, test_size))\n",
    "\n",
    "for i in tqdm(range(train_size)):\n",
    "    img = cv2.imread('./train/%s.jpg' % labels['id'][i])\n",
    "    img = cv2.resize(img, dsize=(height, height))\n",
    "    img = img[:, :, ::-1]\n",
    "    train[i] = img\n",
    "    \n",
    "for i in tqdm(range(test_size)):\n",
    "    img = cv2.imread('./test/%s.jpg' % test_labels['id'][i])\n",
    "    img = cv2.resize(img, dsize=(height, height))\n",
    "    img = img[:, :, ::-1]\n",
    "    test[i] = img\n",
    "    \n",
    "print('Training Data Size = %.2f GB' % (sys.getsizeof(train)/1024**3))\n",
    "print('Testing Data Size = %.2f GB' % (sys.getsizeof(test)/1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = resnet50.preprocess_input(train)\n",
    "test = resnet50.preprocess_input(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dog Breeds: 120\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv')\n",
    "test_labels = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "breeds = list(set(labels['breed']))\n",
    "breeds.sort()\n",
    "print(\"Total Dog Breeds:\", len(breeds))\n",
    "\n",
    "Y_train = np.zeros((train_size, len(breeds)), dtype=np.uint8)\n",
    "for i in range(train_size):\n",
    "    onehot = breeds.index(labels['breed'][i])\n",
    "    Y_train[i][onehot] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_gap(MODEL, preprocess=None, batch_size=128):\n",
    "    x = Input(shape=(height, height, 3))\n",
    "    if preprocess is not None:\n",
    "        x = Lambda(preprocess)(x)\n",
    "    model = MODEL(include_top=False, input_tensor=x, weights='imagenet', pooling='avg')\n",
    "    train_gap = model.predict(train, batch_size=batch_size)\n",
    "    test_gap = model.predict(test, batch_size=batch_size)\n",
    "    with h5py.File(\"gap_%s.h5\" % MODEL.__name__, 'w') as f:\n",
    "        f.create_dataset('train', data=train_gap)\n",
    "        f.create_dataset('test', data=test_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_gap(InceptionV3, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(Xception, xception.preprocess_input, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(InceptionResNetV2, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 5632\n"
     ]
    }
   ],
   "source": [
    "train_temp = []\n",
    "test_temp = []\n",
    "# 'gap_InceptionV3.h5', 'gap_Xception.h5', 'gap_ResNet50.h5', 'gap_InceptionResNetV2.h5'\n",
    "for gapfile in ['gap_InceptionV3.h5', 'gap_Xception.h5', 'gap_InceptionResNetV2.h5']:\n",
    "    with h5py.File(gapfile, 'r') as f:\n",
    "        train_temp.append(np.array(f['train']))\n",
    "        test_temp.append(np.array(f['test']))\n",
    "train_gap = np.concatenate(train_temp, axis=1)\n",
    "test_gap = np.concatenate(test_temp, axis=1)\n",
    "print(\"Number of Features:\", train_gap.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_gap, Y_train, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 675960, Non-Trainable: 0\n"
     ]
    }
   ],
   "source": [
    "# Input Shape: (Batch Size, Feature Vector length)\n",
    "x = Input(shape=(X_train.shape[1],))\n",
    "y = Dropout(0.2)(x)\n",
    "y = Dense(120, activation='softmax', kernel_initializer='he_normal', name='classifier')(y)\n",
    "model_gap = Model(inputs=x, outputs=y, name='GAP')\n",
    "model_gap.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "print('Trainable: %d, Non-Trainable: %d' % get_params_count(model_gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10222/10222 [==============================] - 3s - loss: 0.7017 - acc: 0.8620     \n",
      "Epoch 2/5\n",
      "10222/10222 [==============================] - 2s - loss: 0.2120 - acc: 0.9332     \n",
      "Epoch 3/5\n",
      "10222/10222 [==============================] - 2s - loss: 0.1865 - acc: 0.9395     \n",
      "Epoch 4/5\n",
      "10222/10222 [==============================] - 2s - loss: 0.1738 - acc: 0.9452     \n",
      "Epoch 5/5\n",
      "10222/10222 [==============================] - 2s - loss: 0.1674 - acc: 0.9464     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241d36272e8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Callbacks for Model Checkpoint, Early Stopping and Tensorboard.\n",
    "log_name = '/DogBreed-EP{epoch:02d}-LOSS{val_loss:.4f}.h5'\n",
    "log_dir = datetime.now().strftime('gap_model_%Y%m%d_%H%M')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "mc = ModelCheckpoint(log_dir + log_name, monitor='val_loss', save_best_only=True)\n",
    "tb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model_gap.fit(x=X_train, y=y_train, batch_size=16, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc, tb])\n",
    "\n",
    "# model_gap.fit(x=train_gap, y=Y_train, shuffle=True, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_gap.load_weights('./gap_model_20171015_2231/DogBreed-EP08-LOSS0.2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = model_gap.predict(test_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels.iloc[:, 1:] = y_test\n",
    "test_labels.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
