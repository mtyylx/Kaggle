{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from utils import get_params_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.applications import inception_v3, xception, resnet50, vgg16, vgg19\n",
    "from keras.applications import InceptionV3, Xception, ResNet50, VGG16, VGG19\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10222, Test: 10357\n",
      "Total Dog Breeds: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 10222/10222 [00:30<00:00, 336.75it/s]\n",
      "100%|█████████████████████████████████████████████████████| 10357/10357 [00:30<00:00, 338.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 17.55 GB\n",
      "Testing Data Size = 17.78 GB\n"
     ]
    }
   ],
   "source": [
    "height = 240\n",
    "width = 320\n",
    "train_name = os.listdir('./train')\n",
    "test_name = os.listdir('./test')\n",
    "train_size = len(train_name)\n",
    "test_size = len(test_name)\n",
    "train = np.zeros((train_size, 240, 320, 3), dtype=np.float64)\n",
    "test = np.zeros((test_size, 240, 320, 3), dtype=np.float64)\n",
    "print(\"Train: %d, Test: %d\" % (train_size, test_size))\n",
    "\n",
    "labels = pd.read_csv('labels.csv')\n",
    "test_labels = pd.read_csv('sample_submission.csv')\n",
    "breeds = list(set(labels['breed']))\n",
    "breeds.sort()\n",
    "print(\"Total Dog Breeds:\", len(breeds))\n",
    "\n",
    "Y_train = np.zeros((train_size, len(breeds)), dtype=np.uint8)\n",
    "for i in range(train_size):\n",
    "    onehot = breeds.index(labels['breed'][i])\n",
    "    Y_train[i][onehot] = 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(train_size)):\n",
    "    img = cv2.imread('./train/%s.jpg' % labels['id'][i])\n",
    "    img = cv2.resize(img, dsize=(320, 240))\n",
    "    img = img[:, :, ::-1]\n",
    "    train[i] = img\n",
    "    \n",
    "for i in tqdm(range(test_size)):\n",
    "    img = cv2.imread('./test/%s.jpg' % test_labels['id'][i])\n",
    "    img = cv2.resize(img, dsize=(320, 240))\n",
    "    img = img[:, :, ::-1]\n",
    "    test[i] = img\n",
    "    \n",
    "print('Training Data Size = %.2f GB' % (sys.getsizeof(train)/1024**3))\n",
    "print('Testing Data Size = %.2f GB' % (sys.getsizeof(test)/1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = resnet50.preprocess_input(train)\n",
    "test = resnet50.preprocess_input(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_gap(MODEL, preprocess=None, batch_size=128):\n",
    "    x = Input(shape=(height, width, 3))\n",
    "    if preprocess is not None:\n",
    "        x = Lambda(preprocess)(x)\n",
    "    model = MODEL(include_top=False, input_tensor=x, weights='imagenet', pooling='avg')\n",
    "    train_gap = model.predict(train, batch_size=batch_size)\n",
    "    test_gap = model.predict(test, batch_size=batch_size)\n",
    "    with h5py.File(\"gap_%s.h5\" % MODEL.__name__, 'w') as f:\n",
    "        f.create_dataset('train', data=train_gap)\n",
    "        f.create_dataset('test', data=test_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_gap(InceptionV3, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(Xception, xception.preprocess_input, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_gap(InceptionResNetV2, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_gap(ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 2048\n"
     ]
    }
   ],
   "source": [
    "train_temp = []\n",
    "test_temp = []\n",
    "# 'gap_InceptionV3.h5', 'gap_Xception.h5', 'gap_ResNet50.h5', 'gap_InceptionResNetV2.h5'\n",
    "for gapfile in ['gap_ResNet50.h5']:\n",
    "    with h5py.File(gapfile, 'r') as f:\n",
    "        train_temp.append(np.array(f['train']))\n",
    "        test_temp.append(np.array(f['test']))\n",
    "train_gap = np.concatenate(train_temp, axis=1)\n",
    "test_gap = np.concatenate(test_temp, axis=1)\n",
    "print(\"Number of Features:\", train_gap.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_gap, Y_train, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 245880, Non-Trainable: 0\n"
     ]
    }
   ],
   "source": [
    "# Input Shape: (Batch Size, Feature Vector length)\n",
    "x = Input(shape=(X_train.shape[1],))\n",
    "y = Dropout(0.2)(x)\n",
    "y = Dense(120, activation='softmax', kernel_initializer='he_normal', name='classifier')(y)\n",
    "model_gap = Model(inputs=x, outputs=y, name='GAP')\n",
    "model_gap.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "print('Trainable: %d, Non-Trainable: %d' % get_params_count(model_gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/20\n",
      "8177/8177 [==============================] - 2s 249us/step - loss: 2.5430 - acc: 0.4236 - val_loss: 1.4102 - val_acc: 0.6631\n",
      "Epoch 2/20\n",
      "8177/8177 [==============================] - 2s 239us/step - loss: 1.0469 - acc: 0.7454 - val_loss: 0.9897 - val_acc: 0.7413\n",
      "Epoch 3/20\n",
      "8177/8177 [==============================] - 2s 215us/step - loss: 0.7279 - acc: 0.8112 - val_loss: 0.8519 - val_acc: 0.7535\n",
      "Epoch 4/20\n",
      "8177/8177 [==============================] - 2s 213us/step - loss: 0.5808 - acc: 0.8431 - val_loss: 0.7750 - val_acc: 0.7692\n",
      "Epoch 5/20\n",
      "8177/8177 [==============================] - 2s 207us/step - loss: 0.4883 - acc: 0.8663 - val_loss: 0.7373 - val_acc: 0.7736\n",
      "Epoch 6/20\n",
      "8177/8177 [==============================] - 2s 201us/step - loss: 0.4289 - acc: 0.8770 - val_loss: 0.7084 - val_acc: 0.7819\n",
      "Epoch 7/20\n",
      "8177/8177 [==============================] - 2s 221us/step - loss: 0.3775 - acc: 0.8953 - val_loss: 0.6833 - val_acc: 0.7873\n",
      "Epoch 8/20\n",
      "8177/8177 [==============================] - 2s 223us/step - loss: 0.3404 - acc: 0.9029 - val_loss: 0.6813 - val_acc: 0.7824\n",
      "Epoch 9/20\n",
      "8177/8177 [==============================] - 2s 196us/step - loss: 0.3183 - acc: 0.9089 - val_loss: 0.6561 - val_acc: 0.7902\n",
      "Epoch 10/20\n",
      "8177/8177 [==============================] - 2s 226us/step - loss: 0.2868 - acc: 0.9205 - val_loss: 0.6599 - val_acc: 0.7946\n",
      "Epoch 11/20\n",
      "8177/8177 [==============================] - 2s 228us/step - loss: 0.2751 - acc: 0.9212 - val_loss: 0.6569 - val_acc: 0.7888\n",
      "Epoch 12/20\n",
      "8177/8177 [==============================] - 2s 205us/step - loss: 0.2512 - acc: 0.9292 - val_loss: 0.6605 - val_acc: 0.7824\n",
      "Epoch 13/20\n",
      "8177/8177 [==============================] - 2s 208us/step - loss: 0.2351 - acc: 0.9326 - val_loss: 0.6429 - val_acc: 0.7912\n",
      "Epoch 14/20\n",
      "8177/8177 [==============================] - 2s 220us/step - loss: 0.2191 - acc: 0.9404 - val_loss: 0.6577 - val_acc: 0.7897\n",
      "Epoch 15/20\n",
      "8177/8177 [==============================] - 2s 217us/step - loss: 0.2098 - acc: 0.9425 - val_loss: 0.6471 - val_acc: 0.7936\n",
      "Epoch 16/20\n",
      "8177/8177 [==============================] - 2s 213us/step - loss: 0.1982 - acc: 0.9458 - val_loss: 0.6468 - val_acc: 0.7907\n",
      "Epoch 17/20\n",
      "8177/8177 [==============================] - 2s 234us/step - loss: 0.1884 - acc: 0.9491 - val_loss: 0.6552 - val_acc: 0.7907\n",
      "Epoch 18/20\n",
      "8177/8177 [==============================] - 2s 208us/step - loss: 0.1778 - acc: 0.9497 - val_loss: 0.6491 - val_acc: 0.7897\n",
      "Epoch 19/20\n",
      "8177/8177 [==============================] - 2s 217us/step - loss: 0.1715 - acc: 0.9519 - val_loss: 0.6699 - val_acc: 0.7868\n",
      "Epoch 20/20\n",
      "8177/8177 [==============================] - 2s 213us/step - loss: 0.1641 - acc: 0.9540 - val_loss: 0.6592 - val_acc: 0.7927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e19ddea400>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Callbacks for Model Checkpoint, Early Stopping and Tensorboard.\n",
    "log_name = '/DogBreed-EP{epoch:02d}-LOSS{val_loss:.4f}.h5'\n",
    "log_dir = datetime.now().strftime('gap_model_%Y%m%d_%H%M')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "mc = ModelCheckpoint(log_dir + log_name, monitor='val_loss', save_best_only=True)\n",
    "tb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model_gap.fit(x=X_train, y=y_train, batch_size=16, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc, tb])\n",
    "\n",
    "# model_gap.fit(x=train_gap, y=Y_train, shuffle=True, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train, Y_train, shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def finetune(MODEL, preprocess, height, freeze_till, lr, nb_epoch, opt='SGD', weights=None):\n",
    "    # Preprocess: Standardization\n",
    "    x = Input(shape=(height, height, 3))\n",
    "    x = Lambda(preprocess)(x)\n",
    "\n",
    "    # Base Model: Freeze all conv layers\n",
    "    base_model = MODEL(include_top=False, input_tensor=x, weights='imagenet', pooling='avg')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    if freeze_till is not None:\n",
    "        for layer in base_model.layers[:freeze_till]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Customized Classifier\n",
    "    y = Dropout(0.2)(base_model.output)\n",
    "    y = Dense(120, activation='softmax', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Full Model: Pre-train Conv + Customized Classifier\n",
    "    model = Model(inputs=base_model.input, outputs=y, name='Transfer_Learning')\n",
    "    if opt == 'SGD':\n",
    "        opt = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    print('Trainable: %d, Non-Trainable: %d' % get_params_count(model))\n",
    "    \n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    # Prepare Callbacks for Model Checkpoint, Early Stopping and Tensorboard.\n",
    "    log_name = '/DogBreed-EP{epoch:02d}-LOSS{val_loss:.4f}.h5'\n",
    "    log_dir = datetime.now().strftime('transfer_model_%Y%m%d_%H%M')\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint(log_dir + log_name, monitor='val_loss', save_best_only=True)\n",
    "    tb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    model.fit(x=X_train, y=y_train, batch_size=64, epochs=nb_epoch, \n",
    "              validation_data=(X_val, y_val), callbacks=[es, mc, tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD, LR 0.045, 1 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 7034264, Non-Trainable: 14073096\n",
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/1\n",
      "8177/8177 [==============================] - 87s 11ms/step - loss: 1.3072 - acc: 0.7047 - val_loss: 0.5674 - val_acc: 0.8186\n"
     ]
    }
   ],
   "source": [
    "finetune(Xception, xception.preprocess_input, height=299, freeze_till=116, lr=0.045, nb_epoch=1, opt='SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD, LR 0.001, 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 11876192, Non-Trainable: 9231168\n",
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/5\n",
      "8177/8177 [==============================] - 108s 13ms/step - loss: 0.3416 - acc: 0.9016 - val_loss: 0.4369 - val_acc: 0.8670\n",
      "Epoch 2/5\n",
      "8177/8177 [==============================] - 106s 13ms/step - loss: 0.2742 - acc: 0.9269 - val_loss: 0.4238 - val_acc: 0.8680\n",
      "Epoch 3/5\n",
      "8177/8177 [==============================] - 106s 13ms/step - loss: 0.2518 - acc: 0.9356 - val_loss: 0.4171 - val_acc: 0.8748\n",
      "Epoch 4/5\n",
      "8177/8177 [==============================] - 105s 13ms/step - loss: 0.2355 - acc: 0.9424 - val_loss: 0.4102 - val_acc: 0.8778\n",
      "Epoch 5/5\n",
      "8177/8177 [==============================] - 105s 13ms/step - loss: 0.2180 - acc: 0.9479 - val_loss: 0.4053 - val_acc: 0.8773\n"
     ]
    }
   ],
   "source": [
    "log = './transfer_model_20171119_1943/DogBreed-EP01-LOSS0.5674.h5'\n",
    "finetune(Xception, xception.preprocess_input, height=299, \n",
    "         freeze_till=86, lr=0.001, nb_epoch=5, opt='SGD', weights=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_gap.load_weights('./gap_model_20171015_2231/DogBreed-EP08-LOSS0.2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = model_gap.predict(test_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels.iloc[:, 1:] = y_test\n",
    "test_labels.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
